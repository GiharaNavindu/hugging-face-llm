{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiharaNavindu/hugging-face-llm/blob/main/OCR-01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpmAQVSehz4l",
        "outputId": "9a547b72-82b3-4a8e-d165-dc56b1a602ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 655ms\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "# Install the AI model libraries and the tunneling tool\n",
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q accelerate bitsandbytes qwen-vl-utils streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from PIL import Image, ImageDraw\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- APP SETUP ---\n",
        "st.set_page_config(page_title=\"OCR\", layout=\"wide\")\n",
        "st.title(\"ðŸš€ Qwen 2.5 OCR\")\n",
        "\n",
        "# --- SIDEBAR ---\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload Image\", type=[\"jpg\", \"png\"])\n",
        "temp_path = \"temp.jpg\"\n",
        "\n",
        "if uploaded_file:\n",
        "    image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.sidebar.image(image, caption=\"Uploaded\", use_column_width=True)\n",
        "    image.save(temp_path)\n",
        "\n",
        "# --- MODEL LOADER ---\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    from transformers import BitsAndBytesConfig\n",
        "    # 4-bit quantization for free Colab T4 GPU\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16\n",
        "    )\n",
        "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "        \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
        "    return model, processor\n",
        "\n",
        "# Trigger load\n",
        "if uploaded_file:\n",
        "    with st.spinner(\"Waking up Remote GPU...\"):\n",
        "        model, processor = load_model()\n",
        "\n",
        "    if st.button(\"ðŸ” Extract Text\"):\n",
        "        messages = [{\n",
        "            \"role\": \"user\", \n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": temp_path},\n",
        "                {\"type\": \"text\", \"text\": \"Extract all text from this image.\"}\n",
        "            ]\n",
        "        }]\n",
        "        \n",
        "        # Prepare inputs\n",
        "        text_input = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        image_inputs, _ = process_vision_info(messages)\n",
        "        inputs = processor(\n",
        "            text=[text_input], \n",
        "            images=image_inputs, \n",
        "            padding=True, \n",
        "            return_tensors=\"pt\"\n",
        "        ).to(model.device)\n",
        "        \n",
        "        # Generate\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=1024)\n",
        "        output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "        result = output_text.split(\"assistant\\n\")[-1]\n",
        "        \n",
        "        st.write(\"### Result:\")\n",
        "        st.write(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COPY THIS PASSWORD: 35.203.189.84\n",
            "Streamlit app is running...\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kyour url is: https://great-pumas-win.loca.lt\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "# 1. Get the password for the tunnel\n",
        "print(\"COPY THIS PASSWORD:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "\n",
        "# 2. Run Streamlit in the background\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "print(\"Streamlit app is running...\")\n",
        "\n",
        "# 3. Create the public tunnel\n",
        "!npx localtunnel --port 8501\n",
        "print(\"Tunnel created. Access your app via the provided URL.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMy0qXkYUleKwmLZBvf5ysQ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
